{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get familiar with the concept of a compytation graph, we will create one for the following function\n",
    "\n",
    "<div class=\"MathJax_Display\" style=\"text-align: center;\">\n",
    "\n",
    "$y = \\frac{1}{|x|}\\sum{[(x_i+2)^2 + 3]}$\n",
    "\n",
    "</div>\n",
    "\n",
    "You could imagine that $x$ are our parameters, and we want to optimize (either maximize or minimize) the output $y$. For this, we want to obtain the gradients $\\frac{\\partial{y}}{\\partial{x}}$. For our example, we’ll $\\hat{x} = [0,1,2]$ use  as our input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :  tensor([0., 1., 2.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = t.arange(3, dtype=t.float32, requires_grad=True) # Only float tensor can get gradients\n",
    "print(\"X : \", x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s build the computation graph step by step. You can combine multiple operations in a single line, but we will separate them here to get a better understanding of how each operation is added to the computation graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y :  tensor(12.6667, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a = x + 2\n",
    "b = a**2\n",
    "c = b + 3\n",
    "y = c.mean()\n",
    "print(\"Y : \", y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the statements above, we have created a computation graph that looks similar to the figure below:\n",
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"./img/스크린샷 2023-01-01 오후 11.17.44.png\" style=\"width:20%; height:20%\"/>\n",
    "</p>\n",
    "\n",
    "We can perform backpropagation on the computation graph by calling the function `backward()` on the last output, which effectively calculates the gradients for each tensor that has the property `requires_grad=True`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x.grad` will now contain the gradient $\\frac{\\partial{y}}{\\partial{x}}$ , and this gradient indicates how a change in $\\bold{x}$  will affect output $y$  given the current input $\\bold{x} = [0,1,2]$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3333, 2.0000, 2.6667])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, with the input being $\\bold{x} = [0,1,2]$, our gradients are $\\partial{y}/\\partial{x} = [1.3333, 2.0000, 2.6667]$. The previous code cell should have printed the same result.\n",
    "\n",
    "$x =\\ 원소\\ 갯수 (3개)$\n",
    "\n",
    "$x_i =\\ 원소 (0,1,2 ...)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 | packaged by conda-forge | (main, Nov 22 2022, 08:55:37) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a80da1299cfb6fcf32c2920c6d7840566b2321111569b9b748c12c8898665689"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
